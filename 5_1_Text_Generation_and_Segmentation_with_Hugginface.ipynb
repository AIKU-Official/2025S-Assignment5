{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlIWlCu1cb5y"
   },
   "source": [
    "# Programming Assingnment 5.1 - Text Generation and Segmentation with Hugging Face\n",
    "\n",
    "ì•ˆë…•í•˜ì„¸ìš”, **AIKU í•™íšŒì› ì—¬ëŸ¬ë¶„**. ì–´ëŠë§ ë§ˆì§€ë§‰ ê³¼ì œê°€ ì£¼ì–´ì§€ê²Œ ë˜ì—ˆë„¤ìš”. ê·¸ë™ì•ˆ ê°•ì˜ë¥¼ ë“£ê³  ê³¼ì œë¥¼ í•˜ëŠë¼ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ìŠµë‹ˆë‹¤. ì´ì œ ê±°ì˜ ë§ˆë¬´ë¦¬ ë‹¨ê³„ì´ë‹ˆ, ì¡°ê¸ˆë§Œ ë” í˜ë‚´ì…”ì„œ ëê¹Œì§€ ì˜ ë§ˆë¬´ë¦¬í•´ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤ ğŸ˜Š\n",
    "\n",
    "ë‹¤ì„¯ ë²ˆì§¸ ê³¼ì œì—ì„œëŠ” Hugging Face ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ í•™ìŠµ ë° ì¶”ë¡ ì„ ì§„í–‰í•  ì˜ˆì •ì…ë‹ˆë‹¤. NLPì™€ CV ë¶„ì•¼ì—ì„œ ê°ê° 2ê°œì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©°, ìˆ˜í–‰í•  ì‘ì—…ì€ **í…ìŠ¤íŠ¸ ìƒì„±(Text Generation), ì´ë¯¸ì§€ ë¶„í• (Segmentation), LLM Agent êµ¬ì¶•, ì´ë¯¸ì§€ ìƒì„± (Image Generation)** ì…ë‹ˆë‹¤. ì´ì „ ê³¼ì œë“¤ê³¼ëŠ” ë‹¬ë¦¬, ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸° ë•Œë¬¸ì— ëª¨ë¸ êµ¬ì¡°ë¥¼ ì§ì ‘ êµ¬í˜„í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤. ëŒ€ì‹ , Hugging Faceì—ì„œ ì œê³µí•˜ëŠ” ë‹¤ì–‘í•œ í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ë¥¼ í™œìš©í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì„ ì§ì ‘ êµ¬í˜„í•˜ê³  í•™ìŠµ ë° ì¶”ë¡ í•˜ëŠ” ê³¼ì •ì€ íŠ¹íˆ ì—°êµ¬ ì¸¡ë©´ì—ì„œ ë§¤ìš° ì¤‘ìš”í•˜ì§€ë§Œ, ì´ë¯¸ ê°œë°œëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ í™œìš©í•˜ëŠ” ëŠ¥ë ¥ ë˜í•œ ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ëŠ” ì—°êµ¬ëŠ” ë¬¼ë¡  ëŒ€ë¶€ë¶„ì˜ AI í”„ë¡œì íŠ¸, ê·¸ë¦¬ê³  Kaggleì´ë‚˜ ë°ì´ì½˜ ê°™ì€ ë°ì´í„° ê²½ì§„ ëŒ€íšŒì—ì„œë„ í•„ìˆ˜ì ì¸ ëŠ¥ë ¥ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆ ê³¼ì œê³¼ì œëŠ” ì—¬ëŸ¬ë¶„ì´ Hugging Faceì— ìµìˆ™í•´ì§€ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ Hugging Faceë¥¼ ëŠ¥ìˆ™í•˜ê²Œ ë‹¤ë£¨ëŠ” ì‹¤ë ¥ì„ í‚¤ìš¸ ìˆ˜ ìˆê¸°ë¥¼ ë°”ëë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ka6H2paBcm85"
   },
   "source": [
    "![](https://miro.medium.com/v2/resize:fit:1000/1*09M-TxFBwUVSteNYAiIcpg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wm7BGAYLcy5d"
   },
   "source": [
    "## Part 1. Text Generation with KoGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lS-c6WnCc0Bn"
   },
   "source": [
    "### 1-1. Pip install & Imports\n",
    "í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ pipë¥¼ ì´ìš©í•´ì„œ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nps-lwDmZA1y",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate datasets tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmvfJSEudBmZ"
   },
   "source": [
    "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•˜ê³ , deviceë¥¼ GPUë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ë§Œ, ì½”ë“œë¥¼ êµ¬í˜„í•˜ëŠ” ê³¼ì •ì—ì„œëŠ” **CPU ì‚¬ìš©**ì„ ê¶Œì¥ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "GPUê°€ ê°€ì¥ ë§ì´ í•„ìš”í•œ ë‹¨ê³„ëŠ” í•™ìŠµí•˜ëŠ” ê³¼ì •ì¸ë° êµ¬í˜„í•˜ëŠ” ì‹œê°„ë™ì•ˆ colabì˜ GPUë¥¼ ë‹¤ ì¨ë²„ë¦¬ë©´ ë§‰ìƒ í•™ìŠµí•  ë•Œ í•„ìš”í•œ GPU ìì›ì„ ì“¸ ìˆ˜ ì—†ê²Œ ë©ë‹ˆë‹¤. ë”°ë¼ì„œ ì½”ë“œë¥¼ ëª¨ë‘ êµ¬í˜„í•˜ê³  train ì½”ë“œê°€ ì˜ ëŒì•„ê°€ëŠ”ì§€ í™•ì¸í•œ ë’¤ì— colab ìƒë‹¨ ëŸ°íƒ€ì„ ë©”ë‰´ì—ì„œ ëŸ°íƒ€ì„ ìœ í˜•ì„ GPUë¡œ ë°”ê¾¼ ë’¤ì— ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YZsPcGDW-mj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerFast,\n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    GPT2LMHeadModel\n",
    ")\n",
    "\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('using device: ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "866QOidl5Ena"
   },
   "source": [
    "### 1-2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_v36njL6rdJ"
   },
   "source": [
    "ì•„ë˜ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì„œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ ì£¼ì„¸ìš”. ì—¬ëŸ¬ë¶„ë“¤ê»˜ì„œ ì‚¬ìš©í•˜ì‹¤ ë°ì´í„°ì…‹ì€\n",
    "**[í•œêµ­ì–´ ì¼ìƒ ì† ê³µê°í˜• ëŒ€í™” ë°ì´í„°ì…‹](https://huggingface.co/datasets/Smoked-Salmon-s/empathetic_dialogues_ko)** ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì¼ìƒ ì† ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì‚¬ìš©ìì™€ ì±—ë´‡ ê°„ì˜ ëŒ€í™”ë¥¼ ë‹´ì€ ë°ì´í„°ì…‹ì´ê³  GPT4, GPT3.5-turboë¡œ ì œì‘ëœ ë°ì´í„°ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹µë³€ì€ [ê³µê°ì  í‘œí˜„ - ì¼ë°˜ì ì¸ ëŒ€í™” - ê´€ë ¨ëœ ì§ˆë¬¸] ì˜ í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤.\n",
    "\n",
    "í•´ë‹¹ ë°ì´í„°ì…‹ì€ ì‹±ê¸€-í„´, 2-í„´, 3-í„´ ëŒ€í™”ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ê³¼ì œì—ì„œëŠ” ì‹±ê¸€-í„´ ë°ì´í„°ë§Œ í™œìš©í•©ë‹ˆë‹¤. ì•„ë˜ `filter_dataset` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ì‹±ê¸€-í„´ ë°ì´í„°ë§Œìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë„ë¡ í•„í„°ë§ì„ í•˜ë©°, ì´ëŠ” Hugging Faceì—ì„œ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ë¬´ì¡°ê±´ í•´ì•¼ í•˜ëŠ” ê³¼ì •ì´ ì•„ë‹Œ, íŠ¹ì • ì¡°ê±´ì— ë”°ë¼ íŠ¹ì • ë°ì´í„°ë§Œì„ ê°€ì ¸ì˜¤ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xf-u1PpUXly0"
   },
   "outputs": [],
   "source": [
    "def filter_dataset(dataset):\n",
    "    filtered_list = []\n",
    "    total = 0\n",
    "    for sample in iter(dataset):\n",
    "        total += 1\n",
    "        if sample['type'] == 'single':\n",
    "              filtered_list.append({'instruction': sample['instruction'], 'output': sample['output']})\n",
    "    print(f\"{len(filtered_list)/total:.2%} of data after filtering.\")\n",
    "    return Dataset.from_list(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vO_6qixmBpG8"
   },
   "outputs": [],
   "source": [
    "datasets = load_dataset(\"Smoked-Salmon-s/empathetic_dialogues_ko\", split=\"train\")\n",
    "datasets = filter_dataset(datasets)   # filteringì„ í–ˆì„ ë•Œì™€ í•˜ì§€ ì•Šì•˜ì„ ë•Œì˜ ì°¨ì´ê°€ ê¶ê¸ˆí•˜ë‹¤ë©´ í•´ë‹¹ ì½”ë“œë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ê³  ì‹¤í–‰í•´ë³´ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ne5Q67K-8OKn"
   },
   "source": [
    "ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ë¥¼ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jlAQAhndXu1-"
   },
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "er_g28of8SBJ"
   },
   "source": [
    "í•´ë‹¹ ë°ì´í„°ì…‹ì€ training setìœ¼ë¡œë§Œ êµ¬ì„±ì´ ë˜ì–´ ìˆì–´, Hugging Faceì˜ `train_test_split` í•¨ìˆ˜ë¥¼ í™œìš©í•´ì„œ test setì„ ë§Œë“¤ì–´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71XabCJ4TtCo"
   },
   "outputs": [],
   "source": [
    "train_test_split = datasets.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = train_test_split['train']\n",
    "test_dataset = train_test_split['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h20cxWbK8jQT"
   },
   "source": [
    "ë§Œë“¤ì–´ì§„ training setê³¼ test setì„ `DatasetDict`ë¥¼ í™œìš©í•´ì„œ `dictionary` í˜•íƒœë¡œ ë§Œë“¤ì–´ë´ìš”. ì´ì™€ ê°™ì´ í•˜ëŠ” ì´ìœ ëŠ” ì¡°ê¸ˆ ë’¤ì— ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kGUcNcdWtOs"
   },
   "outputs": [],
   "source": [
    "conversation_datasets = DatasetDict(\n",
    "    {\n",
    "        \"train\": train_dataset,\n",
    "        \"test\": test_dataset,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHfgFw0q89or"
   },
   "source": [
    "`DatasetDict`ë¡œ ë§Œë“¤ì–´ì§„ ë°ì´í„°ì…‹ì˜ í˜•íƒœëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39uKIiJAWzFg"
   },
   "outputs": [],
   "source": [
    "conversation_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjpHCp719e0x"
   },
   "source": [
    "ì´ë²ˆì—ëŠ” ì‹¤ì œë¡œ ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oG1uFIHtZG9R"
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(conversation_datasets[\"train\"]):\n",
    "  if i == 5:\n",
    "    break\n",
    "  for key, value in data.items():\n",
    "     print(f\"{key}: {value}\")\n",
    "  print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxeINzpHOn4j"
   },
   "source": [
    "`transformers`ì˜ `PreTrainedTokenizerFast`ë¥¼ í™œìš©í•´ì„œ tokenizerë¥¼ ë¶ˆëŸ¬ì™€ ì£¼ì„¸ìš”. ëª¨ë¸ ì´ë¦„ì€ `skt/kogpt2-base-v2\"`, `bos_token`ì€ `</s>`, `eos_token`ì€ `</s>`, `unk_token`ì€ `<unk>`, `pad_token`ì€ `<pad>`, `mask_token`ì€ `<mask>` ì…ë‹ˆë‹¤.\n",
    "\n",
    "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì£¼ì„¸ìš”:\n",
    "[PreTrainedTokenizerBase\n",
    "](https://huggingface.co/docs/transformers/v4.44.0/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.from_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEagXQZFQ2ZZ"
   },
   "outputs": [],
   "source": [
    "# TODO: tokenizer êµ¬í˜„\n",
    "tokenizer ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Znqz6QW-Sqyn"
   },
   "source": [
    "ë§Œë“¤ì–´ì§„ training setê³¼ test setì„ `DatasetDict`ë¥¼ í™œìš©í•´ì„œ `dictionary` í˜•íƒœë¡œ ë§Œë“  ì´ìœ ëŠ” ì•„ë˜ ì½”ë“œì— ìˆëŠ” [DatasetDict.map](https://huggingface.co/docs/datasets/v2.20.0/en/package_reference/main_classes#datasets.DatasetDict.map)ì„ í™œìš©í•˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤. Pythonì˜ `map` í•¨ìˆ˜ì™€ ê°™ì´ `DatasetDict.map` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ë°ì´í„°ì…‹ì— ìˆëŠ” ê°ê°ì˜ ë°ì´í„° ìƒ˜í”Œì— ëŒ€í•´ íŠ¹ì • í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ì „ì²˜ë¦¬ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆì‹œë¥¼ í•˜ë‚˜ ë³´ì—¬ë“œë¦¬ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "```\n",
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"rotten_tomatoes\")\n",
    "def add_prefix(example):\n",
    "    example[\"text\"] = \"Review: \" + example[\"text\"]\n",
    "    return example\n",
    "ds = ds.map(add_prefix)\n",
    "\n",
    "ds[\"train\"][0:3][\"text\"]\n",
    "#['Review: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
    "# 'Review: the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson's expanded vision of j . r . r . tolkien's middle-earth .',\n",
    "# 'Review: effective but too-tepid biopic']\n",
    "\n",
    "```\n",
    "ìœ„ í•¨ìˆ˜ì—ì„œëŠ” `map`í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ê°ì˜ ë°ì´í„° ìƒ˜í”Œì— ëŒ€í•´ 'Review'ë¼ëŠ” prefixë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "ê³¼ì œì—ì„œëŠ” `tokenize`ë¼ëŠ” í•¨ìˆ˜ë¥¼ ë³„ë„ë¡œ êµ¬í˜„í•˜ê³  `DatasetDict.map`ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤.\n",
    " `tokenize`í•¨ìˆ˜ì—ì„œ ë°ì´í„°ê°€ ëª¨ë¸ì— ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ í•´ì•¼í•˜ëŠ” ì¼ì€\n",
    "1. ìì—°ì–´ì¸ tokenì„ token idë¡œ ë³€í™˜(encoding)\n",
    "2. `instruction` ê³¼ `output`ì„ êµ¬ë¶„í•  tokenë„ ì¶”ê°€\n",
    "3. ë°ì´í„°ì…‹ keyê°’ì„ `input_ids`ë¡œ ë³€í™˜\n",
    "\n",
    "ì´ë ‡ê²Œ 3ê°€ì§€ì…ë‹ˆë‹¤.\n",
    "\n",
    "2ë²ˆì—ì„œ `instruction`ê³¼ `output`ì„ êµ¬ë¶„í•  tokenì„ ì¶”ê°€í•˜ëŠ” ì´ìœ ëŠ” ì•„ë˜ ê·¸ë¦¼ì— ë‚˜ì˜¨ ì˜ˆì‹œë¥¼ ì´ìš©í•´ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤\n",
    "![](https://jalammar.github.io/images/gpt2/decoder-only-transformer-translation.png)\n",
    "![](https://jalammar.github.io/images/gpt2/decoder-only-summarization.png)\n",
    "ê¸°ê³„ë²ˆì—­ taskì—ì„œ ì˜ì–´-í”„ë‘ìŠ¤ì–´ ë²ˆì—­ì´ë¼ í–ˆì„ ë•Œ ì˜ì–´ ë¬¸ì¥ê³¼ ëŒ€ì‘ë˜ëŠ” í”„ë‘ìŠ¤ì–´ ë¬¸ì¥ë¥¼ êµ¬ë¶„í•  `<to-fr>` tokenì„ ì¶”ê°€í•˜ê³ , ìš”ì•½ taskì—ì„œëŠ” ìš”ì•½ ëŒ€ìƒ(article)ê³¼ ìš”ì•½ë³¸(summary)ì„ êµ¬ë¶„í•  `<summarize>` tokenì„ ì¶”ê°€í•©ë‹ˆë‹¤. ë§Œì•½ ì´ë¥¼ êµ¬ë¶„í•  tokenì´ ì—†ì—ˆë‹¤ë©´, ì–´ë””ê¹Œì§€ê°€ ì˜ì–´ ë¬¸ì¥ì¸ì§€, ì–´ë””ê¹Œì§€ê°€ ìš”ì•½ ëŒ€ìƒì¸ì§€ ëª¨ë¸ì´ êµ¬ë¶„í•˜ì§€ ëª»í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì„œë¡œ ë‹¤ë¥¸ ì„±ê²©ì„ ê°€ì§„ textê°€ ë“±ì¥í•  ë•Œ, ì¤‘ê°„ì— tokenì„ ì¶”ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬ë¶„í•˜ê³¤ í•©ë‹ˆë‹¤.\n",
    "\n",
    "3ë²ˆì—ì„œ ë°ì´í„°ì…‹ keyê°’ì„ `input_ids`ë¡œ ë³€í™˜í•˜ëŠ” ì´ìœ ëŠ” Hugging Faceì—ì„œ ë°ì´í„° ì²˜ë¦¬ ì¸í„°í˜ì´ìŠ¤ì™€ ê´€ë ¨ì´ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€ ì¡°ê¸ˆ ë’¤ì— ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vbDtCiEzdrJ5"
   },
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    # ì§ˆë¬¸, ë ˆì´ë¸” ì‘ë‹µ ë¬¸ì¥ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    instruction, output = data['instruction'], data['output']\n",
    "\n",
    "    # ë¬¸ì¥ì˜ BOS token : </s>\n",
    "    bos_token = tokenizer.bos_token\n",
    "    # ë¬¸ì¥ì˜ EOS token : </s>\n",
    "    eos_token = tokenizer.eos_token\n",
    "\n",
    "    sentence = tokenizer.encode(\n",
    "        # TODO : ë°ì´í„°ë¥¼ \"BOS + ì…ë ¥ + <unused0>(í† í°ìœ¼ë¡œ êµ¬ë¶„) + ì¶œë ¥ + EOS\" í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
    "        text=\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        )\n",
    "\n",
    "    data['input_ids'] = sentence\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "tokenized_datasets = conversation_datasets.map(\n",
    "    tokenize, remove_columns=conversation_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKROPCWp5Puj"
   },
   "source": [
    "### 1-3. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICdMeC0eZcjE"
   },
   "source": [
    "#### 1-3-1. Load Model\n",
    "\n",
    "ì‚¬ìš©í•  ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³  parameter ê°œìˆ˜ë„ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6iuJOnDmlJed"
   },
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2').to(device)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"KoGPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2knjTjDbatk"
   },
   "source": [
    "ëª¨ë¸ ë‚´ë¶€ êµ¬ì¡°ë„ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFu5mcVWgU1j"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9yV_6TrcHes"
   },
   "source": [
    "ìœ„ì˜ ì¶œë ¥ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ KoGPTì˜ ëª¨ë¸ êµ¬ì¡°ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…ë“œë¦¬ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "![](https://jalammar.github.io/images/xlnet/transformer-decoder-intro.png)\n",
    "#### 1. **Main Components**\n",
    "- **`GPT2LMHeadModel`**: GPT-2 ê¸°ë³¸ transformer modelê³¼ linear language model headê°€ ê²°í•©ëœ ìµœìƒìœ„ ëª¨ë“ˆë¡œ, sequenceì˜ ë‹¤ìŒ tokenì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.\n",
    "\n",
    "#### 2. **Transformer Model**\n",
    "- **`transformer`: GPT2Model**\n",
    "  - **`wte`: Embedding(51200, 768)**: Token embedding matrixë¡œ input tokenì˜ idê°’ì„ ì´ìš©í•´ 768-dimensional vectorë¡œ ë§¤í•‘í•©ë‹ˆë‹¤. ì–´íœ˜ í¬ê¸°ëŠ” 51,200ì´ê³  ì´ëŠ” ê³ ìœ í•œ token (id) ê°’ì´ 51200ê°œë¼ëŠ” ì˜ë¯¸ì…ë‹ˆë‹¤.\n",
    "  - **`wpe`: Embedding(1024, 768)**: Position embedding matrixë¡œ ìµœëŒ€ ê¸¸ì´ëŠ” 1024ì´ê³  token embeddingê³¼ ë§ˆì°¬ê°€ì§€ë¡œ 768-dimensional vectorë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "  - **`drop`: Dropout(p=0.1, inplace=False)**: Dropout layerë¡œ ì„ì˜ì˜ ê°’ì„ trainingë•Œ 0ìœ¼ë¡œ ì„¤ì •í•´ overfittingì„ ë°©ì§€í•©ë‹ˆë‹¤.\n",
    "#### 3. **Decoder Blocks**\n",
    "- **`h`: ModuleList**\n",
    "  - 12ê°œì˜ ë™ì¼í•œ ë ˆì´ì–´(**`GPT2Block`**)ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ê° ë ˆì´ì–´ëŠ” ë‹¤ìŒì˜ í•˜ìœ„ ëª¨ë“ˆì„ í¬í•¨í•©ë‹ˆë‹¤:\n",
    "    - **`ln_1`: LayerNorm**: Layer normalization\n",
    "    - **`attn`: GPT2SdpaAttention**\n",
    "      - **`c_attn`: Conv1D()**: ì…ë ¥ê°’ì„ query, key, valueê°’ìœ¼ë¡œ projectí•´ì£¼ëŠ” Convolution layer\n",
    "      - **`c_proj`: Conv1D()**: Masked Self-Attentionì˜ outputì„ embeddingì˜ feature spaceë¡œ ë‹¤ì‹œ project í•´ì£¼ëŠ” Convolution layer\n",
    "      - **`attn_dropout`: Dropout(p=0.1, inplace=False)**: Dropout\n",
    "      - **`resid_dropout`: Dropout(p=0.1, inplace=False)**: Dropout\n",
    "    - **`ln_2`: LayerNorm**: Layer Normalization\n",
    "    - **`mlp`: GPT2MLP**\n",
    "      - **`c_fc`: Conv1D()**: 768 dimensionì—ì„œ ë” ë†’ì€ ì¤‘ê°„ ì°¨ì›(ì¼ë°˜ì ìœ¼ë¡œ 4ë°° í°)ìœ¼ë¡œ ì°¨ì›ì„ í™•ì¥í•˜ëŠ” Convolution layerì…ë‹ˆë‹¤.\n",
    "      - **`c_proj`: Conv1D()**: `c_fc` layerì˜ outputì„ ë‹¤ì‹œ 768 dimensionìœ¼ë¡œ projectí•´ì£¼ëŠ” Convolution layerì…ë‹ˆë‹¤.\n",
    "      - **`act`: NewGELUActivation()**: GELU activation function\n",
    "      - **`dropout`: Dropout(p=0.1, inplace=False)**: Dropout\n",
    "\n",
    "#### 4. **Output Normalization**\n",
    "- **`ln_f`: LayerNorm((768,), eps=1e-05, elementwise_affine=True)**: Layer Normalization\n",
    "\n",
    "#### 5. **Language Model Head**\n",
    "- **`lm_head`: Linear(in_features=768, out_features=51200, bias=False)**: A linear layer used to map the output of the transformer to logits corresponding to the vocabulary size. This is where the model predicts the next token in the sequence. ìµœì¢… outputì„ vocabulary sizeì— ë§ì¶° logitìœ¼ë¡œ ë³€í™˜í•´ì£¼ëŠ” linear layerì…ë‹ˆë‹¤. ëª¨ë¸ì´ sequenceì˜ ë‹¤ìŒ tokenì„ ì˜ˆì¸¡í•˜ëŠ” ìœ„ì¹˜ì…ë‹ˆë‹¤.\n",
    "\n",
    "**ê°‘ìê¸° `Conv1D()`ê°€ ë“±ì¥í•´ì„œ ë‹¹í™©í•˜ì‹¤ ìˆ˜ ìˆëŠ”ë°, ìƒˆë¡œìš´ê±´ ì—†ê³  ì—¬ëŸ¬ë¶„ë“¤ê»˜ì„œ ë°°ìš°ì‹  self-attention mechanismì—ì„œ query, key, valueê°’ì„ ë§Œë“œëŠ” ê³¼ì •ì— í•„ìš”í•œ layerë¼ê³  ì´í•´í•˜ì‹œë©´ ë©ë‹ˆë‹¤. Convolution layerë¥¼ í™œìš©í–ˆì„ ë¿ ë³¸ì§ˆì€ ë‹¬ë¼ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤!**\n",
    "\n",
    "ì„¤ëª…ì´ ë¶€ì¡±í•˜ë‹¤ë©´ ë‹¤ìŒ ìë£Œë¥¼ ì°¸ê³ í•˜ì…”ë„ ì¢‹ê³  ì§ˆë¬¸ë„ ì–¸ì œë“ ì§€ í™˜ì˜ì…ë‹ˆë‹¤!\n",
    "\n",
    "[Illustrated GPT2](https://jalammar.github.io/illustrated-gpt2/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_KZYga8ZoBm"
   },
   "source": [
    "### 1-3-2. Data Collator\n",
    "\n",
    "[DataCollatorForLanguageModeling](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling) ë¥¼ ì‚¬ìš©í•´ `data_collator`ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë¦„ì´ ìµìˆ™í•˜ì§€ ì•Šë‚˜ìš”? ê³¼ì œ3ì—ì„œ ì„œìˆ í˜• ë¬¸ì œì¤‘ì—\n",
    "\n",
    "```\n",
    "`DataLoader`ì—ì„œ `collate_fn` parameterì˜ ì—­í• ì´ë‘ ì•„ë˜ì— ì •ì˜ëœ `collate_batch` í•¨ìˆ˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n",
    "```\n",
    "ì´ë¼ëŠ” ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°„ë‹¨í•˜ê²Œ ì„¤ëª…ì„ í•˜ìë©´ [`DataLoader`ì—ì„œ `collate_fn`ì€ ë°ì´í„°ë¥¼ batch ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë©ë‹ˆë‹¤.](https://pytorch.org/docs/stable/data.html#dataloader-collate-fn). Pytorchì—ì„œ `DataLoader`ì˜ `collate_fn`ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì²˜ëŸ¼ Hugging Faceì—ì„œëŠ” `Data Collator`ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , ê³¼ì œì—ì„œëŠ” Language Modelingì— ì ìš©ë˜ëŠ” `DataCollatorForLanguageModeling`ì„ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "Generalí•œ `DataLoader`ì˜ `collate_fn`ê³¼ ë‹¬ë¦¬, Hugging Faceì˜ `Data Collator` classëŠ” NLPì— íŠ¹í™”ë˜ì–´ ìˆê³  ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆëŠ” ì—¬ëŸ¬ methodê°€ ìˆë‹¤ëŠ” ì ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "ìœ„ì—ì„œ ë°ì´í„°ì…‹ keyê°’ì„ `input_ids`ë¡œ ë³€í™˜í•œ ì´ìœ ëŠ” `DataCollatorForLanguageModeling`ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œì…ë‹ˆë‹¤.\n",
    "\n",
    "`out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])` ì´ ì½”ë“œê°€ ì‹¤í–‰ë  ë•Œ ì‹¤ì œë¡œëŠ” ì•„ë˜ í•¨ìˆ˜ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.\n",
    "```\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        # Handle dict or lists with proper padding and conversion to tensor.\n",
    "        if isinstance(examples[0], Mapping):\n",
    "            batch = pad_without_fast_tokenizer_warning(\n",
    "                self.tokenizer, examples, return_tensors=\"pt\", pad_to_multiple_of=self.pad_to_multiple_of\n",
    "            )\n",
    "        else:\n",
    "            batch = {\n",
    "                \"input_ids\": _torch_collate_batch(examples, self.tokenizer, pad_to_multiple_of=self.pad_to_multiple_of)\n",
    "            }\n",
    "\n",
    "        # If special token mask has been preprocessed, pop it from the dict.\n",
    "        special_tokens_mask = batch.pop(\"special_tokens_mask\", None)\n",
    "        if self.mlm:\n",
    "            batch[\"input_ids\"], batch[\"labels\"] = self.torch_mask_tokens(\n",
    "                batch[\"input_ids\"], special_tokens_mask=special_tokens_mask\n",
    "            )\n",
    "        else:\n",
    "            labels = batch[\"input_ids\"].clone()\n",
    "            if self.tokenizer.pad_token_id is not None:\n",
    "                labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "            batch[\"labels\"] = labels\n",
    "        return batch\n",
    "```\n",
    "ì¦‰, ë°ì´í„°ì— keyê°’ìœ¼ë¡œ `input_ids`ê°€ ìˆì–´ì•¼ë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤. ì½”ë“œê°€ ì›Œë‚™ ê¸¸ì–´ì„œ ì¼ë¶€ë¶„ë§Œ ê°€ì ¸ì™”ëŠ”ë°, ì¶”ê°€ì ì¸ ì„¤ëª…ì„ ì›í•˜ì‹œë©´ ë§ì”€í•´ì£¼ì„¸ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUIOcN2TlxUl"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0vfhOr8ZrcI"
   },
   "source": [
    "### 1-3-3. Trainer\n",
    "\n",
    "ê·¸ë™ì•ˆì˜ ê³¼ì œì—ì„œëŠ” ì—¬ëŸ¬ë¶„ë“¤ê»˜ì„œ ì§ì ‘ Pytorchë¥¼ í™œìš©í•´ í•™ìŠµì„ ìœ„í•œ ì½”ë“œë¥¼ êµ¬í˜„í•´ì™”ìŠµë‹ˆë‹¤. Hugging Faceì—ì„œëŠ” Pytorchì—ì„œì²˜ëŸ¼ í•™ìŠµì„ í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer) classê°€ ìˆìŠµë‹ˆë‹¤. ìì£¼ ì‚¬ìš©í•˜ëŠ” í´ë˜ìŠ¤ì´ë‹ˆ í•´ë‹¹ ë§í¬ì— ë“¤ì–´ê°€ì„œ ê°„ë‹¨í•˜ê²Œë¼ë„ í•œë²ˆ ì½ì–´ë³´ì‹œëŠ”ê±¸ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. í†µìƒì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤(**hyperparameter ê°’ë“¤ì€ ì„ì˜ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. ê°ê°ì˜ parameterê°€ ì•„ë‹Œ ì „ì²´ì ì¸ êµ¬ì¡°ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”**):\n",
    "```\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"codeparrot-ds\",\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")\n",
    "trainer.train()\n",
    "```\n",
    "ë³´í†µ `TrainingArguments`ì—ì„œëŠ” hyperparameterë¥¼ ë¹„ë¡¯í•´ trainingê³¼ ê´€ë ¨ëœ configurationì„ ì •ì˜í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  `Trainer`ì—ëŠ” í•™ìŠµì— ì‚¬ìš©ë  model, tokenizer, data collator, train dataset, eval dataset, `TrainingArguments`ë¡œ ì •ì˜í•œ ë³€ìˆ˜ë¥¼ ì¸ìë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.\n",
    "\n",
    "ê³¼ì œì—ì„œ êµ¬í˜„í•  `Trainer`ì—ì„œëŠ” ìœ„ì—ì„œ ì •ì˜í•œ `model`, `tokenizer`, `data_collator`, `tokenized_datasets[\"train\"]`, `tokenized_datasets[\"test\"]`ë¥¼ ì‚¬ìš©í•˜ë©´ ë˜ê³  `TrainingArguments`ë¡œ ì •ì˜í•œ `args`ë„ ì…ë ¥ê°’ìœ¼ë¡œ ë„£ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "**Training lossëŠ” 2 ì´í•˜ë¡œ ë–¨ì–´ì ¸ì•¼ í†µê³¼ì…ë‹ˆë‹¤! í•™ìŠµì€ 10-20ë¶„ ì •ë„ ê±¸ë¦´ ì˜ˆì •ì…ë‹ˆë‹¤.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBlCL6QKnLfW"
   },
   "outputs": [],
   "source": [
    "# TODO: TrainingArguments, Trainer ì´ìš©í•´ì„œ í•™ìŠµ\n",
    "args =\n",
    "trainer ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zX44kymv5WT9"
   },
   "source": [
    "### 1-4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pql9up7SZuWG"
   },
   "source": [
    "ì˜ˆì‹œ 5ê°œë¥¼ ë§Œë“¤ì–´ì„œ ì§ì ‘ ê²°ê³¼ë¥¼ ì¶œë ¥í•´ë³´ì„¸ìš”. í•™ìŠµ ë•Œì™€ ë§ˆì°¬ê°€ì§€ë¡œ, ì…ë ¥ê³¼ ì¶œë ¥ì„ êµ¬ë¶„ì§“ê¸° ìœ„í•´ `<unused0>` tokenì„ ì‚½ì…í•´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nT0EmVULtdSp"
   },
   "outputs": [],
   "source": [
    "text_1 = ''\n",
    "text_2 = ''\n",
    "text_3 = ''\n",
    "text_4 = ''\n",
    "text_5 = ''\n",
    "textset = [text_1, text_2, text_3, text_4, text_5]\n",
    "\n",
    "for text in textset:\n",
    "  # TODO: '<unused0>' token ì‚½ì…\n",
    "  sentence =\n",
    "  input_ids = tokenizer.encode(sentence, return_tensors='pt').to(device)\n",
    "  gen_ids = model.generate(input_ids,\n",
    "                            max_length=128,\n",
    "                            repetition_penalty=2.0,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id,\n",
    "                            use_cache=True)\n",
    "  generated = tokenizer.decode(gen_ids[0])\n",
    "  print(f\"Input: {text}\\nOutput: {generated}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11HT_BbwiIwy"
   },
   "source": [
    "`tokenizer.encode()` ëŒ€ì‹  `tokenizer()`ë¥¼ ì‚¬ìš©í•´ë³´ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XfWzN-MKFe2v"
   },
   "outputs": [],
   "source": [
    "for text in textset:\n",
    "  sentence = text + '<unused0>'\n",
    "  input_ids = tokenizer(sentence, return_tensors='pt').to(device)\n",
    "\n",
    "  # TODO: input_ids ê°’ ì „ë‹¬\n",
    "  gen_ids = model.generate(\n",
    "                            max_length=128,\n",
    "                            repetition_penalty=2.0,\n",
    "                            pad_token_id=tokenizer.pad_token_id,\n",
    "                            eos_token_id=tokenizer.eos_token_id,\n",
    "                            bos_token_id=tokenizer.bos_token_id,\n",
    "                            use_cache=True)\n",
    "  generated = tokenizer.decode(gen_ids[0])\n",
    "  print(f\"Input: {text}\\nOutput: {generated}\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fidI-3avNLE1"
   },
   "source": [
    "**`tokenizer.encode()`ì™€ `tokenizer()`ì˜ ì°¨ì´, ê·¸ë¦¬ê³  ì´ì— ë”°ë¼ ì™œ `model.generate()`ì˜ ì…ë ¥ê°’ì´ ë³€í•˜ê²Œ ë˜ëŠ”ì§€ ê·¸ ì´ìœ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFFFUIOqXeuC"
   },
   "source": [
    "# Part 2 Segmentation\n",
    "ì´ë²ˆ íŒŒíŠ¸ì—ì„œëŠ” Transformer ê¸°ë°˜ì˜ Segmentation ëª¨ë¸ì¸ MaskFormerë¥¼, HuggingFaceë¥¼ í™œìš©í•´ í•™ìŠµí•´ë³¼ ê²ƒì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtKWp30SMQon"
   },
   "source": [
    "## 2-1. Pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CIfBlOWIMSUV"
   },
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤\n",
    "# transfomers: huggingfaceì˜ ëª¨ë¸ì„ ê°€ì ¸ì˜¤ë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.\n",
    "# datasets: huggingfaceì˜ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜¤ë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤. (ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë‚˜ ë¬´ì‹œí•˜ê³  ì§„í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤.)\n",
    "# evaluate: huggingfaceì˜ evaluating ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.\n",
    "# albumentations: ì´ë¯¸ì§€ ë°ì´í„°ì˜ data augmentationì„ ë„ì™€ì¤ë‹ˆë‹¤.\n",
    "\n",
    "!pip install --upgrade pip\n",
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q datasets\n",
    "!pip install -q evaluate\n",
    "!pip install -q albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9ehbEgwMU7B"
   },
   "source": [
    "## 2-2. Hugging Face Login\n",
    "í—ˆê¹…í˜ì´ìŠ¤ì˜ ìì›ì„ ì´ìš©í•˜ê¸° ìœ„í•´ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "https://huggingface.co/\n",
    "\n",
    "í—ˆê¹…í˜ì´ìŠ¤ ì‚¬ì´íŠ¸ì— ë“¤ì–´ê°€ì„œ íšŒì›ê°€ì… ë° ë¡œê·¸ì¸ì„ í•˜ê³ ,\n",
    "\n",
    "ìš°ì¸¡ ìƒë‹¨ í”„ë¡œí•„ -> Settings -> Access Tokens -> Create new token -> Read tokenì„ ë°œê¸‰í•˜ê³ ,\n",
    "\n",
    "ì•„ë˜ ì…€ì„ ì‹¤í–‰ì‹œí‚¨ ë’¤ ë°œê¸‰ëœ í‚¤ë¥¼ ë„£ìœ¼ë©´ ë˜ê² ìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cmjgcSPoMWDJ"
   },
   "outputs": [],
   "source": [
    "# huggingfaceì— ì ‘ê·¼í•˜ê¸° ìœ„í•´ access tokenìœ¼ë¡œ ë¡œê·¸ì¸í•©ë‹ˆë‹¤.\n",
    "import huggingface_hub\n",
    "huggingface_hub.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxPSf5Y4MYVQ"
   },
   "source": [
    "## 2-3. Load Dataset\n",
    "í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ segmentation ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œ ë°›ê³ , ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "ì €í¬ê°€ ì‚¬ìš©í•  ë°ì´í„°ì…‹ì€ sidewalk-semantic ì…ë‹ˆë‹¤.\n",
    "&nbsp;\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "í•´ë‹¹ ë°ì´í„°ì…‹ì€ ì¸ë„ë¥¼ ì´¬ì˜í•œ ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì„ ì´ 35ê°œì˜ ë ˆì´ë¸”ë¡œ annotation í•´ë†“ì€, semantic segmentation ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "ë°ì´í„°ì…‹ì´ ë‹¤ìš´ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´, ì•„ë˜ ë§í¬ë¡œ ê°€ì„œ ìŠ¹ì¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”!\n",
    "\n",
    "\n",
    "https://huggingface.co/datasets/segments/sidewalk-semantic\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "ë°ì´í„°ì…‹ì˜ êµ¬ì„±ì€ ë§¤ìš° ê°„ë‹¨í•©ë‹ˆë‹¤!\n",
    "\n",
    "`['pixel_values']`ì—ëŠ” ì›ë³¸ ì´ë¯¸ì§€ê°€, `['label']`ì—ëŠ” semantic segmentationì„ ìœ„í•œ segmentation mapì´ ë“¤ì–´ìˆìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCg6njGvMY9Z"
   },
   "outputs": [],
   "source": [
    "# í•™ìŠµ ë°ì´í„°ì…‹ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"segments/sidewalk-semantic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8PRheg4OMa7C"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UYGdd8deMbs9"
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ì„ ì„ê³  trainê³¼ testë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "dataset = dataset.shuffle(seed=1)\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "train_ds = dataset[\"train\"]\n",
    "test_ds = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcvZJQ8oMcwr"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìƒê²¨ë¨¹ì—ˆëŠ”ì§€ í•œ ë²ˆ ë³¼ê¹Œìš”?\n",
    "example = train_ds[0]\n",
    "image = example['pixel_values']\n",
    "segmentation_map = np.array(example['label'])\n",
    "\n",
    "# ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë´…ì‹œë‹¤.\n",
    "plt.axis('off')\n",
    "plt.imshow(image)\n",
    "plt.show(image)\n",
    "\n",
    "# Segmentation mapì„ ë´…ì‹œë‹¤.\n",
    "plt.axis('off')\n",
    "plt.imshow(segmentation_map)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XmmK0NvWMdyC"
   },
   "outputs": [],
   "source": [
    "# Class Labelì„ ìƒ‰ê¹”ë¡œ ë§¤í•‘í•˜ê¸° ìœ„í•œ íŒ”ë ˆíŠ¸ì…ë‹ˆë‹¤.\n",
    "def color_palette():\n",
    "    \"\"\"Color palette that maps each class to RGB values.\n",
    "\n",
    "    This one is actually taken from ADE20k.\n",
    "    \"\"\"\n",
    "    return [[120, 120, 120], [180, 120, 120], [6, 230, 230], [80, 50, 50],\n",
    "            [4, 200, 3], [120, 120, 80], [140, 140, 140], [204, 5, 255],\n",
    "            [230, 230, 230], [4, 250, 7], [224, 5, 255], [235, 255, 7],\n",
    "            [150, 5, 61], [120, 120, 70], [8, 255, 51], [255, 6, 82],\n",
    "            [143, 255, 140], [204, 255, 4], [255, 51, 7], [204, 70, 3],\n",
    "            [0, 102, 200], [61, 230, 250], [255, 6, 51], [11, 102, 255],\n",
    "            [255, 7, 71], [255, 9, 224], [9, 7, 230], [220, 220, 220],\n",
    "            [255, 9, 92], [112, 9, 255], [8, 255, 214], [7, 255, 224],\n",
    "            [255, 184, 6], [10, 255, 71], [255, 41, 10], [7, 255, 255],\n",
    "            [224, 255, 8], [102, 8, 255], [255, 61, 6], [255, 194, 7],\n",
    "            [255, 122, 8], [0, 255, 20], [255, 8, 41], [255, 5, 153],\n",
    "            [6, 51, 255], [235, 12, 255], [160, 150, 20], [0, 163, 255],\n",
    "            [140, 140, 140], [250, 10, 15], [20, 255, 0], [31, 255, 0],\n",
    "            [255, 31, 0], [255, 224, 0], [153, 255, 0], [0, 0, 255],\n",
    "            [255, 71, 0], [0, 235, 255], [0, 173, 255], [31, 0, 255],\n",
    "            [11, 200, 200], [255, 82, 0], [0, 255, 245], [0, 61, 255],\n",
    "            [0, 255, 112], [0, 255, 133], [255, 0, 0], [255, 163, 0],\n",
    "            [255, 102, 0], [194, 255, 0], [0, 143, 255], [51, 255, 0],\n",
    "            [0, 82, 255], [0, 255, 41], [0, 255, 173], [10, 0, 255],\n",
    "            [173, 255, 0], [0, 255, 153], [255, 92, 0], [255, 0, 255],\n",
    "            [255, 0, 245], [255, 0, 102], [255, 173, 0], [255, 0, 20],\n",
    "            [255, 184, 184], [0, 31, 255], [0, 255, 61], [0, 71, 255],\n",
    "            [255, 0, 204], [0, 255, 194], [0, 255, 82], [0, 10, 255],\n",
    "            [0, 112, 255], [51, 0, 255], [0, 194, 255], [0, 122, 255],\n",
    "            [0, 255, 163], [255, 153, 0], [0, 255, 10], [255, 112, 0],\n",
    "            [143, 255, 0], [82, 0, 255], [163, 255, 0], [255, 235, 0],\n",
    "            [8, 184, 170], [133, 0, 255], [0, 255, 92], [184, 0, 255],\n",
    "            [255, 0, 31], [0, 184, 255], [0, 214, 255], [255, 0, 112],\n",
    "            [92, 255, 0], [0, 224, 255], [112, 224, 255], [70, 184, 160],\n",
    "            [163, 0, 255], [153, 0, 255], [71, 255, 0], [255, 0, 163],\n",
    "            [255, 204, 0], [255, 0, 143], [0, 255, 235], [133, 255, 0],\n",
    "            [255, 0, 235], [245, 0, 255], [255, 0, 122], [255, 245, 0],\n",
    "            [10, 190, 212], [214, 255, 0], [0, 204, 255], [20, 0, 255],\n",
    "            [255, 255, 0], [0, 153, 255], [0, 41, 255], [0, 255, 204],\n",
    "            [41, 0, 255], [41, 255, 0], [173, 0, 255], [0, 245, 255],\n",
    "            [71, 0, 255], [122, 0, 255], [0, 255, 184], [0, 92, 255],\n",
    "            [184, 255, 0], [0, 133, 255], [255, 214, 0], [25, 194, 194],\n",
    "            [102, 255, 0], [92, 0, 255]]\n",
    "\n",
    "palette = color_palette()\n",
    "\n",
    "# segmentationì„ ì›ë³¸ ì´ë¯¸ì§€ì™€ í•©ì³ì„œ visualizeí•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def visualize_segmentation_map(image, segmentation_map):\n",
    "  color_segmentation_map = np.zeros((segmentation_map.shape[0], segmentation_map.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "\n",
    "  for label, color in enumerate(palette):\n",
    "      color_segmentation_map[segmentation_map == label, :] = color\n",
    "\n",
    "  ground_truth_color_seg = color_segmentation_map[..., ::-1]\n",
    "\n",
    "  img = np.array(image) * 0.5 + ground_truth_color_seg * 0.5\n",
    "  img = img.astype(np.uint8)\n",
    "\n",
    "  plt.figure(figsize=(15, 10))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(img)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9j4Yb5uMe8R"
   },
   "outputs": [],
   "source": [
    "# ì›ë³¸ ì´ë¯¸ì§€ì™€ segmentation mapì„ í•©ì³ì„œ ë´…ì‹œë‹¤!\n",
    "visualize_segmentation_map(image, segmentation_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRXlJj0PMg6G"
   },
   "source": [
    "segmentation mapì€ í”½ì…€ í•˜ë‚˜í•˜ë‚˜ê°€ class labelë¡œ ì´ë£¨ì–´ì ¸ìˆìŠµë‹ˆë‹¤. ê°ê°ì˜ ìˆ«ìê°€ ì–´ë– í•œ ì¹´í…Œê³ ë¦¬ë¥¼ ì˜ë¯¸í•˜ëŠ”ì§€ ì•Œì•„ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rsphcfCUMh39"
   },
   "outputs": [],
   "source": [
    "segmentation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qWcIHyWmMivi"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "\n",
    "# huggingface_hubì—ì„œ ê° ë ˆì´ë¸”ì— í•´ë‹¹í•˜ëŠ” classëª…ì„ ê°€ì§€ê³  ì˜µë‹ˆë‹¤.\n",
    "repo_id = f\"segments/sidewalk-semantic\"\n",
    "filename = \"id2label.json\"\n",
    "id2label = json.load(open(hf_hub_download(repo_id, filename, repo_type=\"dataset\"), \"r\"))\n",
    "id2label = {int(k):v for k,v in id2label.items()}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pbsZ2nVvMjww"
   },
   "source": [
    "## 2-4. Data Preprocessing\n",
    "ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™”ìœ¼ë‹ˆ, í•™ìŠµì„ ìœ„í•´ torchì—ì„œ Dataset ëª¨ë“ˆì„ ê°€ì ¸ì˜¤ê³ , ì „ì²˜ë¦¬ë¥¼ í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxAhLhAcMk1i"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Datasetì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "class ImageSegmentationDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset, transform):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Complete Image Preprocessing                                                 #\n",
    "        ################################################################################\n",
    "\n",
    "        # TODO: Get image and segmentation map from dataset\n",
    "        original_image = np.array()\n",
    "        original_segmentation_map = np.array()\n",
    "\n",
    "        # TODO: Transform the image and segmentation map\n",
    "        transformed = self.transform(image=, mask=)\n",
    "        image, segmentation_map = transformed['image'], transformed['mask']\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "        # convert to C, H, W\n",
    "        image = image.transpose(2,0,1)\n",
    "\n",
    "        return image, segmentation_map, original_image, original_segmentation_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HC8RYuAMmvb"
   },
   "source": [
    "albumentation ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ data augmentationê³¼ normalizationì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8axZ-WTJMrV_"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì „ì²˜ë¦¬ì…ë‹ˆë‹¤.\n",
    "train_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=1333), # ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆë¥¼ ëŠ˜ë ¤ì„œ\n",
    "    A.RandomCrop(width=512, height=512), # (512, 512)ì˜ ì‚¬ì´ì¦ˆì˜ ì´ë¯¸ì§€ë¡œ ëœë¤ Cropí•˜ê³ \n",
    "    A.HorizontalFlip(p=0.5), # 0.5ì˜ í™•ë¥ ë¡œ ì¢Œìš° flipì„ ì ìš©í•©ë‹ˆë‹¤.\n",
    "    A.Normalize(), # ì´ë¯¸ì§€ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "])\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì „ì²˜ë¦¬ì…ë‹ˆë‹¤.\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(width=512, height=512), # (512, 512)ì˜ ì‚¬ì´ì¦ˆë¥¼ ê°€ì§€ë„ë¡ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.\n",
    "    A.Normalize(), # ì´ë¯¸ì§€ë¥¼ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "])\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "train_dataset = ImageSegmentationDataset(train_ds, transform=train_transform)\n",
    "test_dataset = ImageSegmentationDataset(test_ds, transform=test_transform)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Answer The Question                                                          #\n",
    "################################################################################\n",
    "\"\"\"\n",
    "Q: train_transformê³¼ test_transformì˜ ëª¨ìŠµì´ ì¡°ê¸ˆ ë‹¤ë¥´ë„¤ìš”. ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?\n",
    "\n",
    "A: (ììœ ë¡­ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”)\n",
    "\"\"\"\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RRbVS_7yqhYY"
   },
   "source": [
    "í—ˆê¹…í˜ì´ìŠ¤ì—ì„œëŠ” ëª¨ë¸ì˜ ì „ì²˜ë¦¬ê¸°ë¥¼ ë”°ë¡œ ì œê³µí•´ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ìœ„ì—ì„œ í–ˆë˜ ì „ì²˜ë¦¬ê°€ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¼ë°˜ì ì¸ ì²˜ë¦¬ì˜€ë‹¤ë©´, ì•„ë˜ì˜ ì „ì²˜ë¦¬ëŠ” ì˜¤ì§ MaskFormerë§Œì„ ìœ„í•œ ì „ì²˜ë¦¬ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyksiAvkMuNE"
   },
   "outputs": [],
   "source": [
    "from transformers import MaskFormerImageProcessor\n",
    "\n",
    "# MaskFormerê°€ ì´ë¯¸ì§€ë¥¼ ë°›ì„ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ì „ì²˜ë¦¬ê¸°ë¥¼ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "preprocessor = MaskFormerImageProcessor(ignore_index=0, reduce_labels=False, do_resize=False, do_rescale=False, do_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8fSKoFkMvI0"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# ëª¨ë¸ì— ë“¤ì–´ê°€ê¸° ì§ì „ ì „ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.\n",
    "def collate_fn(batch):\n",
    "    inputs = list(zip(*batch))\n",
    "    images = inputs[0]\n",
    "    segmentation_maps = inputs[1]\n",
    "    batch = preprocessor(\n",
    "        images,\n",
    "        segmentation_maps=segmentation_maps,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    batch['pixel_values'] = batch['pixel_values'].to(device)\n",
    "    batch['class_labels'] = [data.to(device) for data in batch['class_labels']]\n",
    "    batch['mask_labels'] = [data.to(device) for data in batch['mask_labels']]\n",
    "\n",
    "    batch[\"original_images\"] = inputs[2]\n",
    "    batch[\"original_segmentation_maps\"] = inputs[3]\n",
    "\n",
    "    return batch\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ë¡œë”ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Answer The Question                                                          #\n",
    "################################################################################\n",
    "\"\"\"\n",
    "Q: train_dataloaderëŠ” shuffle=True, test_dataloaderëŠ” shuffle=False ì…ë‹ˆë‹¤.\n",
    "   ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?\n",
    "\n",
    "A: (ììœ ë¡­ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”)\n",
    "\"\"\"\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKllytrRMww_"
   },
   "source": [
    "## 2-5. MaskFormer\n",
    "í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ pretrained MaskFormerë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "\n",
    "í—ˆê¹…í˜ì´ìŠ¤ì˜ MaskFormerì— ëŒ€í•´ ê¶ê¸ˆí•˜ë‹¤ë©´ ì•„ë˜ ë§í¬ë¥¼ ì°¸ì¡°í•´ì£¼ì„¸ìš”!\n",
    "\n",
    "https://huggingface.co/facebook/maskformer-swin-base-ade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7dt71gSbMzRV"
   },
   "source": [
    "<img src='https://drive.google.com/uc?id=148psUqNeMVtjn6BwkfMHSDzBo3wnmEGz'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5cBUFSPMz5c"
   },
   "source": [
    "MaskFormerëŠ” í¬ê²Œ 3ê°œì˜ ëª¨ë“ˆë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.\n",
    "\n",
    "Pixel-Level Module: ì´ë¯¸ì§€ì—ì„œ featureë¥¼ ë½‘ê³ , transformer moduleê³¼ segmentation moduleì— ë“¤ì–´ê°ˆ ì„ë² ë”©ì„ ë½‘ìŠµë‹ˆë‹¤.\n",
    "\n",
    "Transformer Module: DETRê³¼ ìœ ì‚¬í•œ êµ¬ì¡°ì…ë‹ˆë‹¤. Nê°œì˜ learnableí•œ ì¿¼ë¦¬ë¥¼ image featureì™€ attentioní•˜ì—¬ ë˜ë‹¤ë¥¸ featureë¥¼ ë½‘ì•„ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "Segmentation Module: MaskFormerì˜ í•µì‹¬ì…ë‹ˆë‹¤. í”½ì…€ë³„ë¡œ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í–ˆë˜ ê¸°ì¡´ì˜ segmentation ëª¨ë¸ë“¤ê³¼ëŠ” ë‹¬ë¦¬, classì™€ maskë¥¼ ë”°ë¡œ êµ¬í•˜ëŠ” êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë”°ë¡œ êµ¬í˜„ì€ í•˜ì§€ ì•Šê² ì§€ë§Œ, ë°ì´í„° ì „ì²˜ë¦¬ì™€ í•™ìŠµ ê³¼ì •ì„ ë³´ë©° ì¸í’‹ê³¼ ì•„ì›ƒí’‹ì„ í™•ì¸í•´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrKnlUXjM3Ds"
   },
   "outputs": [],
   "source": [
    "from transformers import MaskFormerForInstanceSegmentation\n",
    "\n",
    "# í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì‚¬ì „ í•™ìŠµëœ MaskFormer ëª¨ë¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤!\n",
    "model = MaskFormerForInstanceSegmentation.from_pretrained(\"facebook/maskformer-swin-base-ade\",\n",
    "                                                          id2label=id2label,\n",
    "                                                          ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qt8MYCnDM32K"
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0HoynO7M4rq"
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Define Input                                                                 #\n",
    "################################################################################\n",
    "\n",
    "# TODO: Read data from batch\n",
    "outputs = model(pixel_values=,\n",
    "                class_labels=,\n",
    "                mask_labels=)\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "\n",
    "outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nafB4bG3M59t"
   },
   "source": [
    "## 2-6. Training & Evaluation\n",
    "ì´ì œ ë°ì´í„°ì…‹ê³¼ ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìœ¼ë‹ˆ, í•™ìŠµê³¼ í‰ê°€ë¥¼ ì§„í–‰í•  ì°¨ë¡€ì…ë‹ˆë‹¤.\n",
    "\n",
    "í‰ê°€ ì§€í‘œëŠ” mean_iouë¡œ ì„¤ì •í•˜ì˜€ìŠµë‹ˆë‹¤. mean_iouê°€ ê¶ê¸ˆí•˜ì‹œë‹¤ë©´ êµ¬ê¸€ë§!\n",
    "\n",
    "ë˜ë‹¤ì‹œ í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ mean iouë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” íŒ¨í‚¤ì§€ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3Fx9PdOM65p"
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "# í‰ê°€ì§€í‘œëŠ” mean_iouì…ë‹ˆë‹¤!\n",
    "metric = evaluate.load(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0D93OW-M7hm"
   },
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. (1ì—í­ì— ì•½ 5~6ë¶„ ì •ë„ ê±¸ë¦¬ë‹ˆ ì°¸ê³ í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤!)\n",
    "epochs = 2\n",
    "learning_rate = 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwfWIR7HM8e7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ëª¨ë¸ì„ GPUë¡œ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "running_loss = 0.0\n",
    "num_samples = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  # í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "  print(\"Epoch:\", epoch)\n",
    "  model.train()\n",
    "  for idx, batch in enumerate(tqdm(train_dataloader)):\n",
    "\n",
    "      # íŒŒë¼ë¯¸í„°ì˜ gradientë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      ################################################################################\n",
    "      # TODO:                                                                        #\n",
    "      # Define Input                                                                 #\n",
    "      ################################################################################\n",
    "\n",
    "      # ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "      # TODO: Read data from batch\n",
    "      outputs = model(\n",
    "          pixel_values=,\n",
    "          mask_labels=,\n",
    "          class_labels=,\n",
    "      )\n",
    "\n",
    "      ################################################################################\n",
    "      #                                 END OF YOUR CODE                             #\n",
    "      ################################################################################\n",
    "\n",
    "\n",
    "\n",
    "      ################################################################################\n",
    "      # TODO:                                                                        #\n",
    "      # BackPropagation                                                              #\n",
    "      ################################################################################\n",
    "\n",
    "      # TODO: lossë¥¼ outputsì—ì„œ ê°€ì ¸ì™€ ì—­ì „íŒŒë¥¼ ìˆ˜í–‰\n",
    "      loss =\n",
    "      loss.\n",
    "      optimizer.\n",
    "\n",
    "      ################################################################################\n",
    "      #                                 END OF YOUR CODE                             #\n",
    "      ################################################################################\n",
    "\n",
    "      batch_size = batch[\"pixel_values\"].size(0)\n",
    "      running_loss += loss.item()\n",
    "      num_samples += batch_size\n",
    "\n",
    "      if idx % 100 == 0:\n",
    "        print(\"Loss:\", running_loss/num_samples)\n",
    "\n",
    "  # í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "  model.eval()\n",
    "  for idx, batch in enumerate(tqdm(test_dataloader)):\n",
    "\n",
    "    pixel_values = batch[\"pixel_values\"]\n",
    "\n",
    "    # ì¶”ë¡ ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ê³¼ì •ì—ì„œëŠ” gradientê°€ ê¸°ë¡ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "    with torch.no_grad():\n",
    "      outputs = model(pixel_values=pixel_values.to(device))\n",
    "\n",
    "    original_images = batch[\"original_images\"]\n",
    "    target_sizes = [(image.shape[0], image.shape[1]) for image in original_images]\n",
    "\n",
    "    # ëª¨ë¸ì˜ ì•„ì›ƒí’‹ì„ segmentation mapìœ¼ë¡œ ë§Œë“¤ì–´ ì¤ë‹ˆë‹¤.\n",
    "    predicted_segmentation_maps = preprocessor.post_process_semantic_segmentation(outputs,\n",
    "                                                                                  target_sizes=target_sizes)\n",
    "\n",
    "    ground_truth_segmentation_maps = batch[\"original_segmentation_maps\"]\n",
    "\n",
    "    metric.add_batch(references=ground_truth_segmentation_maps, predictions=predicted_segmentation_maps)\n",
    "\n",
    "  print(\"Mean IoU:\", metric.compute(num_labels = len(id2label), ignore_index = 0)['mean_iou'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcFxBGlyM94S"
   },
   "source": [
    "## 2-7. Inference\n",
    "í•™ìŠµì„ ì™„ë£Œí•˜ì…¨ë‚˜ìš”? ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜ ë°°ì› ëŠ”ì§€ ëˆˆìœ¼ë¡œ í•œ ë²ˆ ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ykb4GQdM-qW"
   },
   "outputs": [],
   "source": [
    "# inferenceë¥¼ í•´ë´…ì‹œë‹¤!\n",
    "batch = next(iter(test_dataloader))\n",
    "with torch.no_grad():\n",
    "  outputs = model(batch[\"pixel_values\"].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bf_eMn4mM_es"
   },
   "outputs": [],
   "source": [
    "original_images = batch[\"original_images\"]\n",
    "target_sizes = [(image.shape[0], image.shape[1]) for image in original_images]\n",
    "predicted_segmentation_maps = preprocessor.post_process_semantic_segmentation(outputs, target_sizes=target_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Coycyg6dNAZS"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "image = batch[\"original_images\"][0]\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3He_ILB6NBQo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ì •ë‹µ ë ˆì´ë¸”ì„ visualize í•©ë‹ˆë‹¤.\n",
    "gt = batch[\"original_segmentation_maps\"][0]\n",
    "visualize_segmentation_map(image, gt)\n",
    "\n",
    "# ëª¨ë¸ì˜ ì¶”ë¡  ê²°ê³¼ë¥¼ visualize í•©ë‹ˆë‹¤.\n",
    "pred = predicted_segmentation_maps[0].cpu().numpy()\n",
    "visualize_segmentation_map(image, pred)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Answer The Question                                                          #\n",
    "################################################################################\n",
    "\"\"\"\n",
    "Q: ê²°ê³¼ê°€ ì–´ë–¤ê°€ìš”?\n",
    "   ê²°ê³¼ë¬¼ì„ ë¶„ì„í•˜ê³ , ê·¸ë ‡ê²Œ ë‚˜ì˜¨ ì´ìœ ì™€ ê°œì„ ë°©ì•ˆì„ ììœ ë¡­ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "\n",
    "A: (ììœ ë¡­ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”)\n",
    "\"\"\"\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
